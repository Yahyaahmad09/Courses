{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9197b03d-685b-4e4a-8f92-c0ac72422756",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#ff5733; text-align:center; font-size:45px;\">üöÄ Hello! I'm <b style=\"color:#33A1FF;\">Yahya Ahmad</b> üëã</h1>\n",
    "\n",
    "<p style=\"font-size:22px; text-align:center; color:#444;\">\n",
    "I'm a beginner passionate about <b style=\"color:#FF914D;\">technology</b>, <b style=\"color:#FF914D;\">machine learning</b>, and <b style=\"color:#FF914D;\">Python programming</b>. \n",
    "I'm excited to learn and grow in the world of <b style=\"color:#33A1FF;\">data science</b> and <b style=\"color:#33A1FF;\">AI</b>. üöÄ\n",
    "</p>\n",
    "\n",
    "<hr style=\"border:2px solid #ff5733; width:80%;\">\n",
    "\n",
    "<h2 style=\"color:#33A1FF; font-size:30px;\">üéØ My Interests:</h2>\n",
    "\n",
    "<ul style=\"font-size:22px; color:#444;\">\n",
    "    <li><b style=\"color:#FF914D;\">Programming</b>: Python </li>\n",
    "    <li><b style=\"color:#FF914D;\">Machine Learning</b>: Exploring PyTorch and TensorFlow</li>\n",
    "    <li><b style=\"color:#FF914D;\">Deep Learning AI</b>: Neural Networks & Computer Vision</li>\n",
    "</ul>\n",
    "\n",
    "<hr style=\"border:2px solid #ff5733; width:80%;\">\n",
    "\n",
    "<h2 style=\"color:#33A1FF; font-size:30px;\">üì¨ Let's Connect!</h2>\n",
    "\n",
    "<ul style=\"font-size:22px; color:#444;\">\n",
    "    <li>üìß <b>Email</b>: <a href=\"mailto:Ya0280780@gmail.com\" style=\"color:#FF914D;\">Ya0280780@gmail.com</a></li>\n",
    "    <li>üîó <b>LinkedIn</b>: <a href=\"https://www.linkedin.com/in/yahya-ahmad-8538312b1/\" style=\"color:#FF914D;\">Yahya Ahmad on LinkedIn</a></li>\n",
    "    <li>üíª <b>GitHub</b>: <a href=\"https://github.com/Yahyaahmad09/Courses\" style=\"color:#FF914D;\">My GitHub Repository</a></li>\n",
    "</ul>\n",
    "\n",
    "<hr style=\"border:2px solid #ff5733; width:80%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281ea983-b15f-46d6-b062-e4076438da2d",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#ff6600;\">üìå Dataset and DataLoader in PyTorch</h1>\n",
    "\n",
    "<h2 style=\"color:#3366cc;\">1Ô∏è‚É£ What is a Dataset class?</h2>\n",
    "<p>\n",
    "A <b>Dataset</b> in PyTorch is a class that helps load and preprocess data. It is usually created by subclassing <code>torch.utils.data.Dataset</code> and defining <code>__len__</code> and <code>__getitem__</code> methods.\n",
    "</p>\n",
    "\n",
    "<h2 style=\"color:#3366cc;\">2Ô∏è‚É£ What is a DataLoader class?</h2>\n",
    "<p>\n",
    "The <b>DataLoader</b> in PyTorch helps in efficient data loading by handling <i>batching, shuffling, and multiprocessing</i>. It works with any dataset that follows the <code>Dataset</code> class structure.\n",
    "</p>\n",
    "\n",
    "<h2 style=\"color:#ff6600;\">‚úÖ Key Benefits</h2>\n",
    "<ul>\n",
    "    <li><b>Efficient Data Loading:</b> Handles large datasets by loading them in small batches.</li>\n",
    "    <li><b>Shuffling:</b> Randomizes data order to improve training.</li>\n",
    "    <li><b>Parallel Processing:</b> Uses multiple workers for faster data loading.</li>\n",
    "</ul>\n",
    "\n",
    "<hr style=\"border:2px solid #ff5733; width:80%;\">\n",
    "\n",
    "<h2 style=\"color:#3366cc;\">üìå Import the Necessary Libraries</h2>\n",
    "<p>Before we begin, let's import the required libraries for working with datasets and dataloaders in PyTorch.</p>\n",
    "\n",
    "<h2 style=\"color:#ff6600;\">üîπ Convert the Data into PyTorch Tensors</h2>\n",
    "<p>We need to convert our data into PyTorch tensors for compatibility with PyTorch models.</p>\n",
    "\n",
    "<h2 style=\"color:#3366cc;\">üöÄ Let's Start Our Workflow</h2>\n",
    "\n",
    "<h3 style=\"color:#ff6600;\">1Ô∏è‚É£ Create a Custom Dataset Class</h3>\n",
    "<p>We define a custom dataset class by implementing three main functions: <code>__init__</code>, <code>__len__</code>, and <code>__getitem__</code>.</p>\n",
    "\n",
    "<h3 style=\"color:#ff6600;\">2Ô∏è‚É£ Create an Object of the Dataset Class</h3>\n",
    "<p>We instantiate the dataset class to store and manage our data efficiently.</p>\n",
    "\n",
    "<h3 style=\"color:#3366cc;\">3Ô∏è‚É£ Create an Object of the DataLoader Class</h3>\n",
    "<p>The DataLoader will help us load the dataset efficiently with batching and shuffling.</p>\n",
    "\n",
    "<h3 style=\"color:#ff6600;\">4Ô∏è‚É£ Use a Loop to Print or Show the Batches</h3>\n",
    "<p>Finally, we use a loop to iterate through the DataLoader and display the data in batches.</p>\n",
    "\n",
    "<hr style=\"border:2px solid #ff5733; width:80%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d35944d-9b5a-4bb0-9523-bc93a79e79c6",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#ff6600;\">Simple Code Example for Dataset and DataLoader classes</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082823f9-9cec-478d-b1d0-d8fc01fdd694",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#3366cc;\">Import the Necessary Labraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcb2e971-e6e2-4238-9268-b3b7d01b6bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb30fadb-20c8-4a20-b556-b98102a5849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 01: create a synthetic classification dataset using sklearn \n",
    "X, y = make_classification(\n",
    "    n_samples=10,          # Number of samples\n",
    "    n_features=2,          # Number of features\n",
    "    n_informative=2,       # Number of  inforative features\n",
    "    n_redundant=0,         # Number of Redundant features (No dulicate )\n",
    "    n_classes=2,           # Number of classes \n",
    "    random_state=42        # For reproductivity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64316ac4-5246-4632-9e78-d0ba209e3d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.06833894, -0.97007347],\n",
       "       [-1.14021544, -0.83879234],\n",
       "       [-2.8953973 ,  1.97686236],\n",
       "       [-0.72063436, -0.96059253],\n",
       "       [-1.96287438, -0.99225135],\n",
       "       [-0.9382051 , -0.54304815],\n",
       "       [ 1.72725924, -1.18582677],\n",
       "       [ 1.77736657,  1.51157598],\n",
       "       [ 1.89969252,  0.83444483],\n",
       "       [-0.58723065, -1.97171753]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4df5a4cf-7d76-4727-ba82-ec8e5b2c2ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6edd51d6-0667-4e70-acd8-9075eb4c58a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aa42e9e-c14d-48cb-a6d3-3571ab1e8747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c46666b-b46a-4481-a123-1cf5e6457097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data into pytorch Tensor \n",
    "X = torch.tensor(X, dtype = torch.float32)\n",
    "y = torch.tensor(y, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba6d063a-11c1-4b9d-a2c6-74ab37d12e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0683, -0.9701],\n",
       "        [-1.1402, -0.8388],\n",
       "        [-2.8954,  1.9769],\n",
       "        [-0.7206, -0.9606],\n",
       "        [-1.9629, -0.9923],\n",
       "        [-0.9382, -0.5430],\n",
       "        [ 1.7273, -1.1858],\n",
       "        [ 1.7774,  1.5116],\n",
       "        [ 1.8997,  0.8344],\n",
       "        [-0.5872, -1.9717]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11759738-6e2b-40ca-860c-eb9523b372f8",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#3366cc;\">Let's start our work flow</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b59bd6e9-760a-4aed-9aba-12f4894fc8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a custom class in whcih three man functions\n",
    "class CustomDataSet(Dataset):\n",
    "# 1:- __init__()\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        \n",
    "# 2:- __len__()\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "\n",
    "# # 3:- __getitem__()\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22fe4ea7-81d4-43d6-93da-7c86e68b758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object of the class\n",
    "dataset = CustomDataSet(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73b67894-ed16-44ba-891e-fa54b8f9e86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17bd9a8a-a225-4e67-a727-26b613f8c3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.9629, -0.9923]), tensor(0))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d68bda26-40a6-4019-a3b9-77448ebe964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the object of DataLoader class\n",
    "dataloader = DataLoader(dataset,batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c0660ed-f0d1-42df-a6d8-42db69752815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7206, -0.9606],\n",
      "        [-2.8954,  1.9769]])\n",
      "tensor([0, 0])\n",
      "--------------------------------------------------\n",
      "tensor([[1.7774, 1.5116],\n",
      "        [1.8997, 0.8344]])\n",
      "tensor([1, 1])\n",
      "--------------------------------------------------\n",
      "tensor([[-0.5872, -1.9717],\n",
      "        [ 1.7273, -1.1858]])\n",
      "tensor([0, 1])\n",
      "--------------------------------------------------\n",
      "tensor([[-1.9629, -0.9923],\n",
      "        [-0.9382, -0.5430]])\n",
      "tensor([0, 1])\n",
      "--------------------------------------------------\n",
      "tensor([[ 1.0683, -0.9701],\n",
      "        [-1.1402, -0.8388]])\n",
      "tensor([1, 0])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Use for loop to print or show the Batches\n",
    "for batch_features, batch_labels in dataloader:\n",
    "    print(batch_features),\n",
    "    print(batch_labels),\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b63b6f-6354-4255-9219-8269c6faa83a",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#ff6600; text-align:center;\">üìä Breast Cancer Dataset Training Pipeline</h1>\n",
    "\n",
    "<p style=\"font-size:22px; text-align:center; color:#444;\">\n",
    "The training pipeline consists of the following steps:\n",
    "</p>\n",
    "<h2 style=\"color:#33A1FF; font-size:30px;\">üìú Code Flow</h2>\n",
    "\n",
    "\n",
    "<p style=\"font-size:22px; text-align:center; color:#444;\">\n",
    "The training pipeline consists of the following steps:\n",
    "</p>\n",
    "\n",
    "<ol style=\"font-size:22px; color:#444;\">\n",
    "    <li>‚úÖ Load the dataset</li>\n",
    "    <li>‚úÖ Basic preprocessing</li>\n",
    "    <li>üöÄ Training Process:\n",
    "        <ul>\n",
    "            <li>‚úÖ Create the model</li>\n",
    "            <li>üîπ Forward pass</li>\n",
    "            <li>üîπ Loss calculation</li>\n",
    "            <li>üîπ Backpropagation</li>\n",
    "            <li>üîπ Parameter update</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>üìä Model evaluation</li>\n",
    "</ol>\n",
    "\n",
    "\n",
    "<hr style=\"border:2px solid #ff5733; width:80%;\">\n",
    "\n",
    "<h2 style=\"color:#ff6600;\">üìå Import the Necessary Libraries</h2>\n",
    "<p>Before we begin, let's import the required libraries for working with datasets and dataloaders in PyTorch.</p>\n",
    "\n",
    "<h2 style=\"color:#3366cc;\">üîπ Convert the Data into PyTorch Tensors</h2>\n",
    "<p>We need to convert our data into PyTorch tensors for compatibility with PyTorch models.</p>\n",
    "\n",
    "<h2 style=\"color:#ff6600;\">üöÄ Let's Start Our Workflow</h2>\n",
    "\n",
    "<h3 style=\"color:#3366cc;\">1Ô∏è‚É£ Create a Custom Dataset Class</h3>\n",
    "<p>We define a custom dataset class by implementing three main functions: <code>__init__</code>, <code>__len__</code>, and <code>__getitem__</code>.</p>\n",
    "\n",
    "<h3 style=\"color:#ff6600;\">2Ô∏è‚É£ Create an Object of the Dataset Class</h3>\n",
    "<p>We instantiate the dataset class to store and manage our data efficiently.</p>\n",
    "\n",
    "<h3 style=\"color:#3366cc;\">3Ô∏è‚É£ Create an Object of the DataLoader Class</h3>\n",
    "<p>The DataLoader will help us load the dataset efficiently with batching and shuffling.</p>\n",
    "\n",
    "<h3 style=\"color:#ff6600;\">4Ô∏è‚É£ Use a Loop to Print or Show the Batches</h3>\n",
    "<p>Finally, we use a loop to iterate through the DataLoader and display the data in batches.</p>\n",
    "\n",
    "<hr style=\"border:2px solid #ff5733; width:80%;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffaddc99-9969-4349-8a4f-658bc22c4817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary labraries\n",
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9c16669-d535-4c35-9190-0deddd7002bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/master/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ea47a34e-75d3-41f1-8615-56c79bfd2465",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['id','Unnamed: 32'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "afa75e58-dda9-465b-8128-5bcaa8e7ea98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  ...  concave points_worst  symmetry_worst  fractal_dimension_worst\n",
       "0        NaN        17.99         10.38  ...                0.2654          0.4601                  0.11890\n",
       "1        NaN        20.57         17.77  ...                0.1860          0.2750                  0.08902\n",
       "2        NaN        19.69         21.25  ...                0.2430          0.3613                  0.08758\n",
       "3        NaN        11.42         20.38  ...                0.2575          0.6638                  0.17300\n",
       "4        NaN        20.29         14.34  ...                0.1625          0.2364                  0.07678\n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8c9c0b0c-ffad-4835-a991-b59e7c459f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the shape of the data \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8b3469f1-c958-4b23-8eda-b4ac6e3d65fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ef6dc395-1f4a-4a9c-9039-842c386fb6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into test and train data \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df.iloc[:, 1:] , df.iloc[:,0], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "be5048d0-343e-4d6e-b054-545efb4e7634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data to same rounding\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d19539d8-a3b2-45bc-b1e6-c7f2ee8688ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.02565842,  0.20684347, -0.91341287, ...,  0.45900548,\n",
       "        -0.46644521,  1.92300706],\n",
       "       [-0.75237481, -1.99815033, -0.76730707, ..., -1.03326992,\n",
       "         0.76188162, -0.5117394 ],\n",
       "       [-0.3100498 , -0.87476402, -0.21716566, ...,  1.24156762,\n",
       "         0.38548386,  3.01613677],\n",
       "       ...,\n",
       "       [-0.08747862, -0.02061905, -0.15513191, ..., -0.51731964,\n",
       "        -0.83974504, -0.42162285],\n",
       "       [-0.83407816, -1.05580561, -0.86321451, ..., -1.4910913 ,\n",
       "        -0.12877151, -0.52027114],\n",
       "       [-0.40302257, -0.65890673, -0.45550585, ..., -0.85798201,\n",
       "        -0.79792307, -1.05777102]], shape=(455, 30))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "91818d8b-997f-4e5e-b287-b7d62cba53f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the data to (0,1)\n",
    "encoder = LabelEncoder()\n",
    "Y_train = encoder.fit_transform(Y_train)\n",
    "Y_test = encoder.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "542949e6-b101-4e15-af9c-f2fb41616918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ab6d93ad-574e-415e-94e8-f31baf603df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the numpy array into tenser\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "Y_test_tensor = torch.from_numpy(Y_test).float()\n",
    "Y_train_tensor = torch.from_numpy(Y_train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "35af6dcb-01d9-482e-ba3b-ae45c6fd78fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455, 30])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aac43384-9d1d-4e0a-8913-7b1dfc78ef60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "63a7c914-d99e-4473-9d6a-6301cad9780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a custom class in whcih three man functions\n",
    "class CustomDataSet(Dataset):\n",
    "# 1:- __init__()\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        \n",
    "# 2:- __len__()\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "\n",
    "# # 3:- __getitem__()\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "64b1a6aa-43a8-48f5-a2cf-214ddf8229cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object of dataset class\n",
    "train_dataset = CustomDataSet(X_train_tensor, Y_train_tensor) \n",
    "test_dataset = CustomDataSet(X_test_tensor, Y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3bb32608-eb95-490b-b5af-9543cfc98a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2.2706,  0.0792,  2.4597,  2.3657,  2.5420,  3.1658,  4.1234,  3.3742,\n",
       "          2.7547,  1.0465,  2.7311,  0.6107,  3.3297,  2.6398, -0.1593,  3.3520,\n",
       "          2.2328,  2.0726,  1.2418,  0.4350,  2.4577,  0.3968,  2.9102,  2.5278,\n",
       "          1.6417,  2.7837,  3.2186,  2.6295,  1.7919,  0.7440]),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "86ed0ffd-26df-43c6-8dd1-5fa25b5ffc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create abject of class Dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "26b533c8-df76-407c-84be-80e9b44110dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "import torch.nn as nn\n",
    "class MySimpleNN(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(MySimpleNN, self).__init__()\n",
    "        self.linear = nn.Linear(num_features, 1)  # Linear layer\n",
    "        self.sigmoid = nn.Sigmoid()  # Sigmoid activation\n",
    "\n",
    "    def forward(self, features):\n",
    "        z = self.linear(features)  # Linear transformation\n",
    "        y_pred = self.sigmoid(z)  # Apply sigmoid\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "258ed5b5-7b77-48cc-8225-c9328d74910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important parameters\n",
    "learning_rate = 0.01\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "162e9545-e5f1-45f8-abc7-5d36364d3a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary cross entropy loss function\n",
    "Loss = nn.BCELoss()\n",
    "\n",
    "# use optimazer \n",
    "optimazwer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8907e39e-0171-4503-a2b0-93f4bf88a2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:0.6904346346855164 \n",
      "Epoch: 2, Loss:0.6904346346855164 \n",
      "Epoch: 3, Loss:0.6904346346855164 \n",
      "Epoch: 4, Loss:0.6904346346855164 \n",
      "Epoch: 5, Loss:0.6904346346855164 \n",
      "Epoch: 6, Loss:0.6904346346855164 \n",
      "Epoch: 7, Loss:0.6904346346855164 \n",
      "Epoch: 8, Loss:0.6904346346855164 \n",
      "Epoch: 9, Loss:0.6904346346855164 \n",
      "Epoch: 10, Loss:0.6904346346855164 \n",
      "Epoch: 11, Loss:0.6904346346855164 \n",
      "Epoch: 12, Loss:0.6904346346855164 \n",
      "Epoch: 13, Loss:0.6904346346855164 \n",
      "Epoch: 14, Loss:0.6904346346855164 \n",
      "Epoch: 15, Loss:0.6904346346855164 \n"
     ]
    }
   ],
   "source": [
    "# Training Pipline \n",
    "# create model\n",
    "model = MySimpleNN(X_train_tensor.shape[1])\n",
    "\n",
    "# define loopabs\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # forward pass \n",
    "    y_pred = model(batch_features)\n",
    "\n",
    "    # loss function\n",
    "    loss = Loss(y_pred,batch_labels.view(-1,1))\n",
    "    \n",
    "    # Backward Pass \n",
    "    loss.backward()\n",
    "    \n",
    "    # Update Parameters\n",
    "    \"\"\" with torch.no_grad():\n",
    "        model.linear.weight -= learning_rate * model.linear.weight.grad\n",
    "        model.linear.bias -= learning_rate * model.linear.bias.grad\"\"\"\n",
    "    \n",
    "    optimazwer.step()\n",
    "\n",
    "    optimazwer.zero_grad()\n",
    "    \n",
    "    print(f'Epoch: {epoch + 1}, Loss:{loss.item()} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2f3b8fb8-bb14-47eb-ae65-47ed4935bc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5047619342803955\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "model.eval()    # set the model to evaluate \n",
    "accuracy_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_labels in test_dataset:\n",
    "        # forward pass\n",
    "        y_pred = model(batch_features)\n",
    "        y_pred = (y_pred > 0.5).float()   # convert the probability to binary prediction\n",
    "\n",
    "        # calculate the accurcy for current batch\n",
    "        batch_accuracy = (y_pred.view(-1) == batch_labels).float().mean()\n",
    "        accuracy_list.append(batch_accuracy)\n",
    "\n",
    "# calculate overall accuray\n",
    "overall_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "print(f'Accuracy: {overall_accuracy.item()}')\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
